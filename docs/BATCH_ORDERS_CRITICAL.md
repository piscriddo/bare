# üö® BATCH ORDERS: THE #1 CRITICAL OPTIMIZATION

## Why Batch Orders Are Non-Negotiable for Arbitrage

### The Core Problem

**Arbitrage requires 2 simultaneous orders:**
```
Order 1: BUY at $0.70 (ask price)
Order 2: SELL at $0.75 (bid price)
Profit: $0.05 per share
```

**What can go wrong with sequential execution:**

1. **Market moves between orders** (200ms window of vulnerability)
   - You execute BUY at $0.70 ‚úì
   - Wait 200ms for confirmation
   - Market moves: Bid drops to $0.71
   - You execute SELL at $0.71
   - **Profit destroyed:** $0.01 instead of $0.05

2. **One-sided exposure** (risk accumulation)
   - You're holding a single position for 200ms
   - Price can move against you
   - Circuit breaker limits might not save you fast enough

3. **Front-running by other bots**
   - Your first order is visible on-chain
   - HFT bots see it and take the opposite leg
   - **Arbitrage opportunity stolen**

4. **Doubled latency**
   - Sequential: 200ms (Order 1) + 200ms (Order 2) = **400ms total**
   - Batch: **200ms total**
   - **50% slower = 50% less likely to win the race**

---

## Performance Impact: Sequential vs Batch

### Sequential Execution (Current Standard)

```rust
// Sequential: 2 HTTP requests (400ms total)
async fn execute_arbitrage_sequential(opportunity: &ArbitrageOpportunity) -> Result<()> {
    // Request 1: BUY order (200ms)
    let buy_response = client.create_order(&CreateOrderParams {
        side: OrderSide::BUY,
        price: opportunity.ask_price,
        size: opportunity.max_size,
        ..
    }).await?;

    // ‚ö†Ô∏è DANGER ZONE: Market can move here! (200ms exposure)

    // Request 2: SELL order (200ms)
    let sell_response = client.create_order(&CreateOrderParams {
        side: OrderSide::SELL,
        price: opportunity.bid_price,
        size: opportunity.max_size,
        ..
    }).await?;

    Ok(())
}
```

**Timeline:**
```
T=0ms:   Send BUY request
T=200ms: BUY confirmed ‚úì
         ‚ö†Ô∏è EXPOSED TO MARKET RISK ‚ö†Ô∏è
T=200ms: Send SELL request
T=400ms: SELL confirmed ‚úì
Total: 400ms
```

**Risks:**
- üö® **200ms one-sided exposure**
- üö® **Market can move between orders**
- üö® **Other bots can see first order and front-run**
- üö® **2x latency = 2x less likely to win**

### Batch Execution (Optimal)

```rust
// Batch: 1 HTTP request (200ms total)
async fn execute_arbitrage_batch(opportunity: &ArbitrageOpportunity) -> Result<()> {
    // Single request with both orders (200ms)
    let responses = client.create_batch_orders(&[
        CreateOrderParams {
            side: OrderSide::BUY,
            price: opportunity.ask_price,
            size: opportunity.max_size,
            ..
        },
        CreateOrderParams {
            side: OrderSide::SELL,
            price: opportunity.bid_price,
            size: opportunity.max_size,
            ..
        },
    ]).await?;

    // Both orders submitted atomically
    Ok(())
}
```

**Timeline:**
```
T=0ms:   Send BOTH orders in single request
T=200ms: Both confirmed ‚úì (or both fail)
Total: 200ms
```

**Benefits:**
- ‚úÖ **50% faster** (200ms vs 400ms)
- ‚úÖ **No one-sided exposure**
- ‚úÖ **Atomic execution** (both succeed or both fail)
- ‚úÖ **Lower front-running risk** (single network operation)
- ‚úÖ **2x better chance of winning the race**

---

## Impact Analysis

### Latency Reduction

| Execution Method | Latency | Improvement |
|------------------|---------|-------------|
| Sequential | 400ms | Baseline |
| Batch (same endpoint) | 200ms | **50% faster** ‚ö° |
| Batch (HTTP/2 multiplexed) | 200ms | **50% faster** ‚ö° |
| Batch (parallel sends*) | ~200ms | **50% faster** ‚ö° |

\* Even parallel sends don't help atomicity

### Win Rate Impact

**Assumptions:**
- Arbitrage opportunities last 500ms on average
- You compete with 10 other bots

**Sequential execution (400ms):**
- Window: 500ms - 400ms = 100ms remaining
- **Win rate: ~10%** (you're slow)

**Batch execution (200ms):**
- Window: 500ms - 200ms = 300ms remaining
- **Win rate: ~30%** (3x better)

**Impact:** Batch orders could **triple your success rate!**

---

## Implementation Strategies

### Strategy 1: Native Batch API (Best)

**If Polymarket CLOB supports batch endpoint:**

```rust
// POST /orders/batch
pub async fn create_batch_orders(&self, orders: &[CreateOrderParams]) -> Result<Vec<OrderResponse>> {
    let response = self.client
        .post(&format!("{}/orders/batch", self.base_url))
        .json(&orders)
        .send()
        .await?;

    response.json().await.map_err(Into::into)
}
```

**Pros:**
- ‚úÖ True atomic execution
- ‚úÖ Single HTTP round-trip
- ‚úÖ Server-side guarantee both orders execute together
- ‚úÖ 50% latency reduction

**Cons:**
- ‚ö†Ô∏è Requires API support (need to verify)

### Strategy 2: HTTP/2 Multiplexing (Fallback)

**If no batch API, use HTTP/2 parallel requests:**

```rust
pub async fn create_orders_parallel(&self, orders: &[CreateOrderParams]) -> Result<Vec<OrderResponse>> {
    // Send both requests simultaneously over single HTTP/2 connection
    let futures: Vec<_> = orders
        .iter()
        .map(|order| self.create_order(order))
        .collect();

    // Wait for both to complete
    let results = futures::future::try_join_all(futures).await?;
    Ok(results)
}
```

**Pros:**
- ‚úÖ Requests sent in parallel
- ‚úÖ Single TCP connection (multiplexed)
- ‚úÖ ~50% latency reduction
- ‚úÖ Works with any API

**Cons:**
- ‚ö†Ô∏è Not truly atomic (one can fail while other succeeds)
- ‚ö†Ô∏è Requires HTTP/2 support
- ‚ö†Ô∏è Both visible on network at same time

### Strategy 3: Optimistic Parallel (Last Resort)

**Send both requests in parallel over HTTP/1.1:**

```rust
pub async fn create_orders_optimistic(&self, orders: &[CreateOrderParams]) -> Result<Vec<OrderResponse>> {
    use tokio::try_join;

    let (buy_result, sell_result) = try_join!(
        self.create_order(&orders[0]),
        self.create_order(&orders[1])
    )?;

    Ok(vec![buy_result, sell_result])
}
```

**Pros:**
- ‚úÖ Works with any API
- ‚úÖ ~50% latency reduction
- ‚úÖ Easy to implement

**Cons:**
- ‚ö†Ô∏è Uses 2 TCP connections (or 2 round-trips on same connection)
- ‚ö†Ô∏è Not atomic (need manual rollback)
- ‚ö†Ô∏è Risk of partial fills

### Comparison

| Strategy | Latency | Atomicity | Requirements |
|----------|---------|-----------|--------------|
| **Native Batch** | 200ms | ‚úÖ Guaranteed | Batch API support |
| **HTTP/2 Multiplex** | ~200ms | ‚ö†Ô∏è Best effort | HTTP/2 support |
| **Optimistic Parallel** | ~200-250ms | ‚ùå Manual rollback | None |
| **Sequential** | 400ms | ‚ùå One-sided risk | None |

---

## Detecting Batch API Support

### Method 1: Check API Documentation

```bash
# Check Polymarket CLOB docs for batch endpoint
curl https://docs.polymarket.com/clob-api
```

Look for endpoints like:
- `POST /orders/batch`
- `POST /orders/bulk`
- `POST /atomic`

### Method 2: Try and Test

```rust
pub async fn test_batch_support(&self) -> bool {
    let test_orders = vec![
        CreateOrderParams { /* dummy order 1 */ },
        CreateOrderParams { /* dummy order 2 */ },
    ];

    // Try batch endpoint
    let response = self.client
        .post(&format!("{}/orders/batch", self.base_url))
        .json(&test_orders)
        .send()
        .await;

    match response {
        Ok(resp) if resp.status().is_success() => {
            tracing::info!("‚úÖ Batch API supported!");
            true
        }
        Ok(resp) if resp.status() == 404 => {
            tracing::warn!("‚ùå Batch API not found (404)");
            false
        }
        _ => {
            tracing::warn!("‚ùå Batch API not supported");
            false
        }
    }
}
```

### Method 3: Check Response Headers

```rust
// Some APIs hint at batch support via headers
if response.headers().get("X-Batch-Support").is_some() {
    // Batch supported
}
```

---

## Rollback Strategy (If No Atomicity)

**If using parallel sends without atomicity:**

```rust
pub async fn execute_with_rollback(&self, opportunity: &ArbitrageOpportunity) -> Result<()> {
    let (buy_result, sell_result) = tokio::try_join!(
        self.create_order(&buy_params),
        self.create_order(&sell_params)
    );

    match (buy_result, sell_result) {
        (Ok(buy), Ok(sell)) => {
            // Both succeeded ‚úì
            Ok(())
        }
        (Ok(buy), Err(sell_error)) => {
            // Buy succeeded, sell failed - DANGEROUS
            tracing::error!("‚ö†Ô∏è One-sided fill! Cancelling buy order...");

            // Try to cancel the buy order
            self.cancel_order(&buy.order_id).await?;

            Err(anyhow!("Partial fill, rolled back"))
        }
        (Err(_), Ok(sell)) => {
            // Sell succeeded, buy failed - DANGEROUS
            tracing::error!("‚ö†Ô∏è One-sided fill! Cancelling sell order...");
            self.cancel_order(&sell.order_id).await?;
            Err(anyhow!("Partial fill, rolled back"))
        }
        (Err(e1), Err(e2)) => {
            // Both failed - safe
            Err(anyhow!("Both orders failed: {:?}, {:?}", e1, e2))
        }
    }
}
```

**Problem:** Cancel might not be instant, leaving you exposed!

---

## Recommended Implementation

### Phase 4 Implementation Plan

**Day 1: Detect batch support**
```rust
// Auto-detect on client initialization
impl ClobClient {
    pub async fn new(config: ClientConfig) -> Result<Self> {
        let client = Self { /* ... */ };

        // Test for batch support
        let supports_batch = client.test_batch_support().await;
        client.batch_mode = if supports_batch {
            BatchMode::Native
        } else if client.supports_http2() {
            BatchMode::Http2Multiplex
        } else {
            BatchMode::Parallel
        };

        Ok(client)
    }
}
```

**Day 2: Implement all strategies**
```rust
pub async fn execute_arbitrage(&self, opp: &ArbitrageOpportunity) -> Result<()> {
    match self.batch_mode {
        BatchMode::Native => self.execute_batch_native(opp).await,
        BatchMode::Http2Multiplex => self.execute_batch_http2(opp).await,
        BatchMode::Parallel => self.execute_batch_parallel(opp).await,
    }
}
```

**Day 3: Add comprehensive error handling**
```rust
// Rollback, retries, circuit breaker integration
```

---

## Performance Targets

### Without Batch Orders
- Detection: 47ns (Phase 2) ‚úÖ
- Execution: **400ms** (sequential HTTP) ‚ö†Ô∏è
- **Total: 400ms** (SLOW)

### With Batch Orders
- Detection: 47ns (Phase 2) ‚úÖ
- Execution: **200ms** (batch HTTP) ‚úÖ
- **Total: 200ms** (2x FASTER)

### Impact
- **2x faster execution**
- **3x better win rate**
- **Eliminates one-sided risk**

---

## Priority Assessment

**Batch orders are #1 priority because:**

1. **Biggest single win:** 50% latency reduction
2. **Risk reduction:** No one-sided exposure
3. **Competitive advantage:** Most bots don't do this
4. **Easy to implement:** 1-2 days of work
5. **Foundational:** Affects every trade

**Without batch orders, you're not competitive in HFT!**

---

## Action Items

- [ ] Day 1: Research Polymarket CLOB batch API
  - Check official docs
  - Test batch endpoint
  - Ask in Discord/community

- [ ] Day 2: Implement Strategy 1 (if supported)
  - Native batch API
  - Atomic execution
  - Error handling

- [ ] Day 3: Implement fallbacks
  - HTTP/2 multiplexing
  - Parallel sends with rollback
  - Auto-detection logic

- [ ] Day 4: Integration testing
  - Test with circuit breaker
  - Measure actual latency
  - Verify atomicity

**This is THE most important optimization. Do it first!** üö®
